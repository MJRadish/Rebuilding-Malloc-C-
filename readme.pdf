There are two types of memory offset information. The first is the data right over the allocated space. The first byte of the memory offset tells the system how many sequential bytes are reserved for the memory offset info before the actual allocated space is reached. This memory offset info is summed up and that sum is the size of the allocated space beneath the info. For example, let's say the user tries to malloc 5 bytes. The representation of the memory would look like 

1
5
5 bytes of allocated space.

So the first line is 1 and the system knows the next 1 line is reserved for the memory offset. It then sums up that next 1 line and now the system knows the next 5 bytes are the allocated space. The first allocated space is the address that is returned by malloc. There can be multiple lines dedicated for the memory offset information since the maximum size a char can hold is 127. So if the size that was malloced was 200, the first line would be 2 then the next following lines would be 127 then 73 and the following would be the returned address. This is an integral part of how my_malloc() works. The function, my_malloc(), first computes how many bytes of memory offset information it needs from the size and then sums that number and size. Let's call this sum total size. So the system then searches through memblock[] in O(n) linear time until it can find a block of unallocated space that's large enough for the total size. Since each unallocated byte is represented as -1 in the memory block, if the system ever sees a value that is not -1 it knows that that value is the first line info of a previously allocated space. The system then counts the memory offset info and “jumps over” the allocated space, subsequently saving time efficiency. If enough -1’s or unallocated space is sequentially found then the system knows it has enough room to allocate space. The system writes the memory offset info to first couple bytes, then the system returns the address of the first byte, located below the first type of memory offset information, back to the user. But before the system returns the appropriate address, the system has to create a Node that corresponds to the address. The system then calls my_malloc() and sends the size of the Node. If the system returns NULL, then the system cannot keep track of the user’s address. So the system resets the just previously allocated space back to the default value and returns NULL. However, if the the Node’s malloc returns an address, then the system knows there is enough space, so the system returns the address that was just allocated to the user, leading to a successful malloc. The next type of memory offset information is the creation of a linked list that keeps track of each allocated space. Before an address is return to the user, a Node must be first malloced. Each Node has an attribute, "addPoint", which points to the address that is about to be returned to the user. This Node is then inserted into the linked list. The reason of doing this is because the system needs to keep track of each address that is allocated since the user might free something that was not allocated by my_malloc or an address in general. This is connected to how my_free() works. So when a user calls free with an address, the system calls searchFree() which searches the linked list for a Node that points to this address. If the Node is not found, or the Node is found and the freeFlag attribute of the Node is set to invalid, my_free() will display the appropriate error message. Once the system knows that this address is valid, it then calls a helper function, my_freeExtra(), which actually free the address. Freeing the address is first accomplished by calculating the first type of memory offset information. This tells the system how many bytes were allocated. The system then sets all of the allocated space and the first type of memory offset information to -1 which effectively represents freeing the information. However, the system does not free the addresses corresponding Node since the system needs to keep track of the freed addresses, since the user can free a address twice in a row-resulting in a error. This system leads to wasting space over the course of mallocing and freeing many times since creating an Node takes up 27 bytes of space(including the memory offset information). To overcome this, if the user ever mallocs and the system deems there is enough space for the user and that first byte was an address that was a previously allocated space, the system will reuse the same Node that pointed to the previously freed address and just sets the freeFlag attribute to the valid bit, thus saving memory. The freeFlag check is performed in my_malloc(), which calls search() before the system tries to malloc a Node. Based on the value returned by search(), my_malloc() decides if a new Node should be created or not.

Findings:
We observed that memgrind test E (.0078 seconds on average) took the longest followed by F(.0021 seconds on average) then followed by B(.0006 seconds on average) then followed by D(.0002 seconds on average) then followed by C(.00005), and test A(.00003 seconds on average) performed on the quickest time.

Observations Between Memgrind Tests A and C:
Test A was the shortest run time which makes sense since you're mallocing the same address over and over again which results in no new node creation, because the same address is being returned. So when the system searches if the address being malloc has a node already associated with it, this just takes O(1) time because just one node will always exist. It is interesting to compare test A totest C since test C has the second quickest time which makes sense since if test A is the lower bound of all cases. Test C is slightly above test A since there are times where the system performs something like free then malloc then free then malloc which results in a case A time(no new node creation), but since its random, C has a chance to create more than one node compared to A. Which could result in more comparisons in searching for unallocated space and more comparisons in searching through the linked list.

Observations Between Memgrind Tests B and D:
It was interesting to see that test B took more time than test D since test D has a change to malloc upwards of 64 bytes at a time. However, if we observe the given conditions, this observation makes sense, because if the system mallocs 150 times, the system will create 150 new nodes because each node has a unique address associated to it. Also, when the system attempts to malloc, it has to linearly search down the memblock, which is expensive in terms of big O notation, when there is upto 150 nodes sequentially in the memblock. Alternatively, in the case for test D, it could result in over mallocing which does waste time, since the system has a chance to free a few times before mallocing. There is a chance the system does indeed malloc the same address in memblock which result in the system using the old node for that address. So when the system searches through the linked list, the system doesn't have to waste time in searching at most 150 nodes.

Observations Between Memgrind Tests F and E:
We were not surprised that test E and F took the longest on average, but something that was interesting was that we noticed that case E was causing a lot of memory maxed out errors which resulted in the time increasing since the system called malloc multiple times before an actually malloc took take place. This would explain why test E took the longest out of all test cases since most malloc calls did not do anything and just wasted time. Also when a free did happen, the freed space had to be enough space for the next malloc. Since malloc can be between 500-1000 bytes, the likelihood of this happening was slim. In the case of F, It was interesting to see on average case F took 10 times longer than case D, which makes sense since case F can create integers, which are 4 bytes and also doubles which are 8 bytes in comparison to 1 byte chars. But at the worst case, F just creates doubles each time. This would result in not 10, but 8 times slower run time. This observation supports our hypothesis that we originally had. Test case F would have a smaller chance of reusing the same node and had to create new nodes, which would result in a greater time complexity.




